{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## CS4830 Project\n",
        "\n",
        "* Aniruddha (ME18B181)\n",
        "* Vasudev Gupta (ME18B182)\n",
        "* Shubham (ME18B183)"
      ],
      "metadata": {
        "id": "XvuVcBed2sMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "from pyspark.ml.feature import StringIndexer, IndexToString, VectorAssembler, OneHotEncoder\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline, PipelineModel"
      ],
      "metadata": {
        "id": "7hyoX2081qxr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"CS4830_project\")\\\n",
        "         .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.4.5\")\\\n",
        "         .getOrCreate()"
      ],
      "metadata": {
        "id": "Db1pGKVc1rHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"gs://big-data-cs4830/project/trainingdatanyc.csv/*.csv\""
      ],
      "metadata": {
        "id": "6AEG82lH1rJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Exploration Steps"
      ],
      "metadata": {
        "id": "44VimJBv11e5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.option(\"header\", \"true\").csv(DATA_PATH)"
      ],
      "metadata": {
        "id": "b-IuFan21rLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.filter(col(\"Violation Precinct\").isNotNull())\n",
        "df.select(\"Violation Precinct\").distinct().count()"
      ],
      "metadata": {
        "id": "Yiq21aiQ1rNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\"Violation Precinct\").distinct().sort(\"Violation Precinct\").show()"
      ],
      "metadata": {
        "id": "pGOQfzjh1rQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "BDdeRBra1rSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.select([count(when(isnan(col) | isnull(col), col)).alias(col) for col in df.columns]).show()"
      ],
      "metadata": {
        "id": "yVYN37bj1rUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removed due to presence of many null values\n",
        "cols_to_drop = ['Time First Observed', 'Intersecting Street', 'Law Section', 'Violation Legal Code', 'To Hours In Effect', 'Unregistered Vehicle?', 'Meter Number', 'Violation Description', 'No Standing or Stopping Violation', 'Hydrant Violation', 'Double Parking Violation', 'Latitude', 'Longitude', 'Community Board', 'Community Council', 'Census Tract', 'BIN', 'BBL', 'NTA']\n",
        "df = df.select([col for col in df.columns if col not in cols_to_drop])"
      ],
      "metadata": {
        "id": "fUwX7ZvA1rWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# handling null values\n",
        "df = df.na.fill('NULL')"
      ],
      "metadata": {
        "id": "aDnCgbkE1rZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df.columns:\n",
        "    print(col, df.select(col).distinct().count())"
      ],
      "metadata": {
        "id": "k-pPva2W1rcG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_columns = [\"Feet From Curb\", \"Violation In Front Of Or Opposite\", \"Issuing Agency\", \"Violation County\", \"Plate Type\", \"Violation Code\", \"Registration State\", \"Issuer Squad\"]\n",
        "df = df.select(input_columns + [\"Violation Precinct\"])"
      ],
      "metadata": {
        "id": "r0KEhnC21reK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "id": "ZBhQYEqL1rgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exporting code for production"
      ],
      "metadata": {
        "id": "OJNNv68s1_Pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_COLUMNS = [\"Feet From Curb\", \"Violation In Front Of Or Opposite\", \"Issuing Agency\", \"Violation County\", \"Plate Type\", \"Violation Code\", \"Registration State\", \"Issuer Squad\"]\n",
        "TARGET_COLUMN = \"Violation Precinct\""
      ],
      "metadata": {
        "id": "lVMYCSjq1ri9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_and_prepare_data(path):\n",
        "    df = spark.read.option(\"header\", \"true\").csv(path)\n",
        "    df = df.filter(col(TARGET_COLUMN).isNotNull())\n",
        "\n",
        "    df = df.na.fill('NULL')    \n",
        "    df = df.select(INPUT_COLUMNS + [TARGET_COLUMN])\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "8M2MgNjK2A8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing data for training & inference"
      ],
      "metadata": {
        "id": "Gs6qKryU2E8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = read_and_prepare_data(DATA_PATH)\n",
        "data.printSchema()"
      ],
      "metadata": {
        "id": "QIt10HNX2A-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_data, val_data = data.randomSplit([0.99, 0.01], seed=42)\n",
        "print({\"train_size\": tr_data.count(), \"val_size\": val_data.count()})"
      ],
      "metadata": {
        "id": "P3vB6io02BA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # just for testing purposes\n",
        "# _, tr_data = data.randomSplit([0.999, 0.001], seed=42)\n",
        "# val_data = tr_data\n",
        "# tr_data.count()"
      ],
      "metadata": {
        "id": "kbmKZO8X2BDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up model pipeline"
      ],
      "metadata": {
        "id": "txfaYQZ72KL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labelIndexer = StringIndexer(inputCol=TARGET_COLUMN, outputCol=\"label\").fit(tr_data)\n",
        "print('labels:', labelIndexer.labels)"
      ],
      "metadata": {
        "id": "Uuqsk9IS2BF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_indexers = [StringIndexer(inputCol=col, outputCol=col+\"_index\") for col in INPUT_COLUMNS]\n",
        "feature_pipeline = Pipeline(stages=feature_indexers).fit(tr_data)"
      ],
      "metadata": {
        "id": "3WS6JtoG2BIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OHE = OneHotEncoder(\n",
        "    inputCols=[col + \"_index\" for col in INPUT_COLUMNS],\n",
        "    outputCols=[col + \"_onehot\" for col in INPUT_COLUMNS],\n",
        ")"
      ],
      "metadata": {
        "id": "HX9b6Kmw2BKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols=[col + \"_onehot\" for col in INPUT_COLUMNS],\n",
        "    outputCol=\"features\",\n",
        ")"
      ],
      "metadata": {
        "id": "zed6Nkg82BMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression(featuresCol=\"features\", labelCol=\"label\", predictionCol=\"class\")\n",
        "index_to_string = IndexToString(inputCol=\"class\", outputCol=\"prediction\", labels=labelIndexer.labels)"
      ],
      "metadata": {
        "id": "vZbHBQoW2BO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stages = [\n",
        "    labelIndexer,\n",
        "    feature_pipeline,\n",
        "    OHE,\n",
        "    assembler,\n",
        "    model,\n",
        "    index_to_string,\n",
        "]\n",
        "pipeline = Pipeline(stages=stages)"
      ],
      "metadata": {
        "id": "Jqx50PAF2BRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = pipeline.fit(tr_data)"
      ],
      "metadata": {
        "id": "UtX5imLG2T1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = \"gs://big-data-cs4830/project/final_model\""
      ],
      "metadata": {
        "id": "pBgdWCng2T4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.save(MODEL_PATH)"
      ],
      "metadata": {
        "id": "odlSkcOF2T6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using model for inference"
      ],
      "metadata": {
        "id": "Otl2nQXZ2XPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# running the model directly for testing\n",
        "pipeline = PipelineModel.load(MODEL_PATH)"
      ],
      "metadata": {
        "id": "_ux_mo202T8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_metric =  MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"class\", metricName=\"accuracy\")\n",
        "f1_metric =  MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"class\", metricName=\"f1\")"
      ],
      "metadata": {
        "id": "QE6yuzyj2BTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tr_pred =  pipeline.transform(tr_data).select(\"class\", \"label\")\n",
        "tr_pred.show()"
      ],
      "metadata": {
        "id": "lB0ZtAdM2Zvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_metric.evaluate(tr_pred), f1_metric.evaluate(tr_pred)"
      ],
      "metadata": {
        "id": "2hg-929Z2Zxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_pred =  pipeline.transform(val_data).select(\"class\", \"label\")\n",
        "val_pred.show()"
      ],
      "metadata": {
        "id": "25v1D2Jk2Z0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_metric.evaluate(val_pred), f1_metric.evaluate(val_pred)"
      ],
      "metadata": {
        "id": "Ovj7VBJU2Z2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kafka Producer"
      ],
      "metadata": {
        "id": "lWgGKhdp2fhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: change following for demo\n",
        "REAL_TIME_DATA_PATH = DATA_PATH\n",
        "BROKER = \"10.128.0.34:9092\"\n",
        "TOPIC = \"CS4830-project\"\n",
        "LIMIT = 200"
      ],
      "metadata": {
        "id": "GeVGIqM92Z4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U -q kafka-python\n",
        "\n",
        "import os\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.1'"
      ],
      "metadata": {
        "id": "dCUkjVsd2Z7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from kafka import KafkaProducer\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "zGCG3KPD2Z9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real_time_df = read_and_prepare_data(REAL_TIME_DATA_PATH)"
      ],
      "metadata": {
        "id": "RvNxNHp82Z_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data file should be small otherwise one needs to allocate bigger cluster\n",
        "real_time_df = real_time_df.limit(LIMIT)"
      ],
      "metadata": {
        "id": "DiCxQr9G2kJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "producer = KafkaProducer(\n",
        "    bootstrap_servers=[BROKER],\n",
        "    value_serializer=lambda x: json.dumps(x).encode('utf-8')\n",
        ")"
      ],
      "metadata": {
        "id": "n3Oe4l1-2kMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pandas_df = real_time_df.toPandas()"
      ],
      "metadata": {
        "id": "hFEBxSbo2kOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in tqdm(pandas_df.iterrows()):\n",
        "    payload = \",\".join(str(x) for x in row.to_dict().values())\n",
        "    producer.send(TOPIC, value = ',' + payload + ',')\n",
        "    producer.flush()"
      ],
      "metadata": {
        "id": "e4UMqDUA2kRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Vs82gT9V2kYD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}